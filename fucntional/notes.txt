from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder.appName("DataFrame Join").getOrCreate()

# Assume df1 and df2 are your DataFrames
# Let's register these DataFrames as SQL temporary views
df1.createOrReplaceTempView("table1")
df2.createOrReplaceTempView("table2")

# Spark SQL query to perform an inner join on the key column 'key_column'
# and select specific columns 'column1' from df1 and 'column2' from df2
query = """
SELECT 
    t1.column1,
    t2.column2,
    t1.key_column
FROM 
    table1 t1
INNER JOIN 
    table2 t2 
ON 
    t1.key_column = t2.key_column
"""

# Execute the query
result_df = spark.sql(query)

# Show the result of the query
result_df.show()
